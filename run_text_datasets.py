"""
Run DiffPrep training and AutoGluon evaluation on all text-named datasets
Ch·∫°y diffprep_fix v√† ƒë√°nh gi√° v·ªõi AutoGluon tr√™n c√°c dataset c√≥ t√™n b·∫±ng ch·ªØ
"""

import subprocess
import sys
import os
import json
import time
from pathlib import Path

# Danh s√°ch c√°c dataset c√≥ t√™n b·∫±ng ch·ªØ (text names)
TEXT_DATASETS = [
    'abalone',
    'ada_prior',
    'avila',
    'connect-4',
    'eeg',
    'google',
    'house_prices',
    'jungle_chess_2pcs_raw_endgame_complete',
    'microaggregation2',
    'mozilla4',
    'obesity',
    'page-blocks',
    'pbcseq',
    'pol',
    'Run_or_walk_information',
    'shuttle',
    'USCensus',
    'wall-robot-navigation'
]

# C·∫•u h√¨nh
METHOD = "diffprep_fix"
SPLIT_SEED = 42
TRAIN_SEED = 1
AUTOGLUON_TIME_LIMIT = 300  # 10 ph√∫t cho m·ªói dataset
DATA_DIR = "data"
RESULT_DIR = "result"
AUTOGLUON_OUTPUT_DIR = "autogluon_results"


def run_command(cmd, description):
    """Ch·∫°y l·ªánh v√† x·ª≠ l√Ω l·ªói"""
    print("\n" + "="*80)
    print(f"{description}")
    print("="*80)
    print(f"Command: {' '.join(cmd)}")
    print()
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=False, text=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå L·ªñI: {description} th·∫•t b·∫°i!")
        print(f"Return code: {e.returncode}")
        return False
    except Exception as e:
        print(f"\n‚ùå L·ªñI: {description} th·∫•t b·∫°i v·ªõi exception: {e}")
        return False


def check_dataset_exists(dataset_name, data_dir=DATA_DIR):
    """Ki·ªÉm tra dataset c√≥ t·ªìn t·∫°i kh√¥ng"""
    dataset_path = os.path.join(data_dir, dataset_name)
    data_file = os.path.join(dataset_path, "data.csv")
    info_file = os.path.join(dataset_path, "info.json")
    
    if not os.path.exists(dataset_path):
        print(f"‚ö†Ô∏è  B·ªè qua {dataset_name}: Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i")
        return False
    
    if not os.path.exists(data_file):
        print(f"‚ö†Ô∏è  B·ªè qua {dataset_name}: Kh√¥ng t√¨m th·∫•y data.csv")
        return False
        
    if not os.path.exists(info_file):
        print(f"‚ö†Ô∏è  B·ªè qua {dataset_name}: Kh√¥ng t√¨m th·∫•y info.json")
        return False
    
    return True


def run_diffprep_training(dataset_name):
    """Ch·∫°y DiffPrep training"""
    cmd = [
        sys.executable,
        "main.py",
        "--dataset", dataset_name,
        "--method", METHOD,
        "--train_seed", str(TRAIN_SEED),
        "--split_seed", str(SPLIT_SEED),
        "--data_dir", DATA_DIR
    ]
    
    return run_command(cmd, f"ƒêang train DiffPrep cho {dataset_name}")


def run_autogluon_evaluation(dataset_name):
    """Ch·∫°y AutoGluon evaluation"""
    cmd = [
        sys.executable,
        "evaluate_with_autogluon.py",
        "--dataset", dataset_name,
        "--method", METHOD,
        "--split_seed", str(SPLIT_SEED),
        "--time_limit", str(AUTOGLUON_TIME_LIMIT),
        "--data_dir", DATA_DIR,
        "--result_dir", RESULT_DIR,
        "--output_dir", AUTOGLUON_OUTPUT_DIR
    ]
    
    return run_command(cmd, f"ƒêang ƒë√°nh gi√° AutoGluon cho {dataset_name}")


def save_summary(results, output_file="text_datasets_summary.json"):
    """L∆∞u t·ªïng k·∫øt k·∫øt qu·∫£"""
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nüìä ƒê√£ l∆∞u t·ªïng k·∫øt v√†o {output_file}")


def print_summary(results):
    """In t·ªïng k·∫øt k·∫øt qu·∫£"""
    print("\n" + "="*80)
    print("üìä T·ªîNG K·∫æT K·∫æT QU·∫¢")
    print("="*80)
    
    successful = [r for r in results if r['status'] == 'success']
    failed = [r for r in results if r['status'] == 'failed']
    skipped = [r for r in results if r['status'] == 'skipped']
    
    print(f"\n‚úÖ Th√†nh c√¥ng: {len(successful)}/{len(results)}")
    print(f"‚ùå Th·∫•t b·∫°i: {len(failed)}/{len(results)}")
    print(f"‚è≠Ô∏è  B·ªè qua: {len(skipped)}/{len(results)}")
    
    if successful:
        print("\n‚úÖ C√°c dataset th√†nh c√¥ng:")
        for r in successful:
            print(f"  - {r['dataset']}")
            if 'autogluon_acc' in r:
                print(f"    AutoGluon Test Acc: {r['autogluon_acc']:.4f}")
    
    if failed:
        print("\n‚ùå C√°c dataset th·∫•t b·∫°i:")
        for r in failed:
            print(f"  - {r['dataset']}: {r.get('error', 'Unknown error')}")
    
    if skipped:
        print("\n‚è≠Ô∏è  C√°c dataset b·ªè qua:")
        for r in skipped:
            print(f"  - {r['dataset']}: {r.get('reason', 'Unknown reason')}")


def main():
    """H√†m ch√≠nh"""
    print("="*80)
    print("üöÄ B·∫ÆT ƒê·∫¶U CH·∫†Y DIFFPREP V√Ä AUTOGLUON CHO C√ÅC DATASET VƒÇN B·∫¢N")
    print("="*80)
    print(f"Ph∆∞∆°ng ph√°p: {METHOD}")
    print(f"Split seed: {SPLIT_SEED}")
    print(f"Train seed: {TRAIN_SEED}")
    print(f"AutoGluon time limit: {AUTOGLUON_TIME_LIMIT}s")
    print(f"T·ªïng s·ªë dataset: {len(TEXT_DATASETS)}")
    print()
    
    results = []
    start_time = time.time()
    
    for i, dataset in enumerate(TEXT_DATASETS, 1):
        print(f"\n{'='*80}")
        print(f"üì¶ DATASET {i}/{len(TEXT_DATASETS)}: {dataset}")
        print(f"{'='*80}")
        
        dataset_start_time = time.time()
        result = {
            'dataset': dataset,
            'status': 'unknown',
            'diffprep_time': 0,
            'autogluon_time': 0
        }
        
        # Ki·ªÉm tra dataset t·ªìn t·∫°i
        if not check_dataset_exists(dataset):
            result['status'] = 'skipped'
            result['reason'] = 'Dataset kh√¥ng t·ªìn t·∫°i ho·∫∑c thi·∫øu file'
            results.append(result)
            continue
        
        # B∆∞·ªõc 1: Train DiffPrep
        print(f"\nüîß B∆∞·ªõc 1/2: Train DiffPrep...")
        diffprep_start = time.time()
        if not run_diffprep_training(dataset):
            result['status'] = 'failed'
            result['error'] = 'DiffPrep training failed'
            results.append(result)
            print(f"\n‚è≠Ô∏è  B·ªè qua {dataset} do l·ªói training")
            continue
        result['diffprep_time'] = time.time() - diffprep_start
        
        # B∆∞·ªõc 2: Evaluate v·ªõi AutoGluon
        print(f"\nüìà B∆∞·ªõc 2/2: ƒê√°nh gi√° v·ªõi AutoGluon...")
        autogluon_start = time.time()
        if not run_autogluon_evaluation(dataset):
            result['status'] = 'failed'
            result['error'] = 'AutoGluon evaluation failed'
            results.append(result)
            print(f"\n‚ö†Ô∏è  {dataset}: Training th√†nh c√¥ng nh∆∞ng evaluation th·∫•t b·∫°i")
            continue
        result['autogluon_time'] = time.time() - autogluon_start
        
        # ƒê·ªçc k·∫øt qu·∫£ AutoGluon
        try:
            ag_result_file = os.path.join(
                AUTOGLUON_OUTPUT_DIR,
                METHOD,
                dataset,
                "result.json"
            )
            if os.path.exists(ag_result_file):
                with open(ag_result_file, 'r') as f:
                    ag_result = json.load(f)
                    result['autogluon_acc'] = ag_result.get('test_acc', 0)
        except Exception as e:
            print(f"‚ö†Ô∏è  Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c k·∫øt qu·∫£ AutoGluon: {e}")
        
        result['status'] = 'success'
        result['total_time'] = time.time() - dataset_start_time
        results.append(result)
        
        print(f"\n‚úÖ Ho√†n th√†nh {dataset} trong {result['total_time']:.1f}s")
        print(f"   - DiffPrep: {result['diffprep_time']:.1f}s")
        print(f"   - AutoGluon: {result['autogluon_time']:.1f}s")
        
        # L∆∞u t·ªïng k·∫øt sau m·ªói dataset
        save_summary(results)
    
    # In t·ªïng k·∫øt cu·ªëi c√πng
    total_time = time.time() - start_time
    print(f"\n‚è±Ô∏è  T·ªïng th·ªùi gian: {total_time/60:.1f} ph√∫t")
    
    print_summary(results)
    save_summary(results)
    
    print("\n" + "="*80)
    print("üéâ HO√ÄN TH√ÄNH!")
    print("="*80)


if __name__ == "__main__":
    main()
